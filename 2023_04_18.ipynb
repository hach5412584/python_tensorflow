{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8adf33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl (272.8 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting jax>=0.3.15\n",
      "\n",
      "  Downloading jax-0.4.8.tar.gz (1.2 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.10.0.2)\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.12.1)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\csie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.53.0-cp39-cp39-win_amd64.whl (4.0 MB)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.22.3-cp39-cp39-win_amd64.whl (420 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\csie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (58.0.4)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.0)\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Downloading ml_dtypes-0.1.0-cp39-cp39-win_amd64.whl (120 kB)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.7.1)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\csie\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.4)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (PEP 517): started\n",
      "  Building wheel for jax (PEP 517): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.8-py3-none-any.whl size=1439795 sha256=95bf49811c50da3cb5692830d5999d5dc052ac66e53acc2abbdc4aefc1b0e805\n",
      "  Stored in directory: c:\\users\\csie\\appdata\\local\\pip\\cache\\wheels\\05\\94\\dc\\81042da9bced43ff430bc02043d213d9e4b210b584c39e31c1\n",
      "Successfully built jax\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, numpy, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, opt-einsum, ml-dtypes, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, libclang, keras, jax, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.53.0 jax-0.4.8 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.1.0 numpy-1.22.4 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.22.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.2 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf71a1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1913b7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a=[1,2,3]\n",
    "print(a)\n",
    "b=tf.convert_to_tensor(a)\n",
    "print(b)\n",
    "c=b.numpy().tolist()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9f60b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1 2 3]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=[1,2,3]\n",
    "print(a)\n",
    " \n",
    "b=np.array(a)\n",
    "print(b)\n",
    " \n",
    "c=b.tolist()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f38e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([1,2,3])\n",
    "print(a)\n",
    "b=tf.convert_to_tensor(a)\n",
    "print(b)\n",
    "c=b.numpy()\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf59aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3], dtype=np.int32)\n",
    "b = [4, 5, 6]\n",
    "\n",
    "t_a = tf.convert_to_tensor(a)\n",
    "t_b = tf.convert_to_tensor(b)\n",
    "\n",
    "print(t_a)\n",
    "print(t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f66a740f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.is_tensor(a), tf.is_tensor(t_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1603e140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones = tf.ones((2, 3))\n",
    "\n",
    "t_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e4a058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ones.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f4fe31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.2   5.    3.142], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "const_tensor = tf.constant([1.2, 5, np.pi], dtype=tf.float32)\n",
    "\n",
    "print(const_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b261b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "t_a_new = tf.cast(t_a, tf.int64)\n",
    "\n",
    "print(t_a_new.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "918cc3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)  -->  (5, 3)\n"
     ]
    }
   ],
   "source": [
    "t = tf.random.uniform(shape=(3, 5))\n",
    "\n",
    "t_tr = tf.transpose(t)\n",
    "print(t.shape, ' --> ', t_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf268653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6)\n"
     ]
    }
   ],
   "source": [
    "t = tf.zeros((30,))\n",
    "\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))\n",
    "\n",
    "print(t_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52454d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 1, 4, 1)  -->  (1, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "t = tf.zeros((1, 2, 1, 4, 1))\n",
    "\n",
    "t_sqz = tf.squeeze(t, axis=(2, 4))\n",
    "\n",
    "print(t.shape, ' --> ', t_sqz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de8d202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "t1 = tf.random.uniform(shape=(5, 2), \n",
    "                       minval=-1.0,\n",
    "                       maxval=1.0)\n",
    "\n",
    "t2 = tf.random.normal(shape=(5, 2), \n",
    "                      mean=0.0,\n",
    "                      stddev=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d31a5994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.27  -0.874]\n",
      " [-0.017 -0.175]\n",
      " [-0.296 -0.139]\n",
      " [-0.727  0.135]\n",
      " [-0.401  0.004]]\n"
     ]
    }
   ],
   "source": [
    "t3 = tf.multiply(t1, t2).numpy()\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05eb3a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.09  0.207], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t4 = tf.math.reduce_mean(t1, axis=0)\n",
    "\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05152841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.144  1.115 -0.87  -0.321  0.856]\n",
      " [ 0.248 -0.191  0.25  -0.064 -0.331]\n",
      " [-0.478  0.407 -0.436  0.022  0.527]\n",
      " [ 0.525 -0.234  0.741 -0.593 -1.194]\n",
      " [-0.099  0.26   0.125 -0.462 -0.396]]\n"
     ]
    }
   ],
   "source": [
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True)\n",
    "\n",
    "print(t5.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17dec039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.711  0.302]\n",
      " [ 0.371 -1.049]]\n"
     ]
    }
   ],
   "source": [
    "t6 = tf.linalg.matmul(t1, t2, transpose_a=True)\n",
    "\n",
    "print(t6.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04bb7e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.046 0.293 0.504 0.96  0.383]\n"
     ]
    }
   ],
   "source": [
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\n",
    "\n",
    "print(norm_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0949bdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.046, 0.293, 0.504, 0.96 , 0.383], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.square(t1), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cb0917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.165 0.901 0.631 0.435 0.292 0.643]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.165, 0.901], dtype=float32),\n",
       " array([0.631, 0.435], dtype=float32),\n",
       " array([0.292, 0.643], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "t = tf.random.uniform((6,))\n",
    "\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, 3)\n",
    "\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ad758e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.165 0.901 0.631 0.435 0.292]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.165, 0.901, 0.631], dtype=float32),\n",
       " array([0.435, 0.292], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((5,))\n",
    "\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, num_or_size_splits=[3, 2])\n",
    "\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e816715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "A = tf.ones((3,))\n",
    "B = tf.zeros((2,))\n",
    "\n",
    "C = tf.concat([A, B], axis=0)\n",
    "print(C.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d16accc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.ones((3,))\n",
    "B = tf.zeros((3,))\n",
    "\n",
    "S = tf.stack([A, B], axis=1)\n",
    "print(S.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a43522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.float32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = [1.2, 3.4, 7.5, 4.1, 5.0, 1.0]\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices(a)\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3794bee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for item in ds:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05774d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: [1.2 3.4 7.5]\n",
      "batch 2: [4.1 5.  1. ]\n"
     ]
    }
   ],
   "source": [
    "ds_batch = ds.batch(3)\n",
    "\n",
    "for i, elem in enumerate(ds_batch, 1):\n",
    "    print('batch {}:'.format(i), elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d236cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
